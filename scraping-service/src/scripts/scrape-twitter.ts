import { TwitterScraper } from "../scrapers/twitter.scraper";
import { saveTweetToSupabase } from "../utils/save-tweets";
import { scrapingLogger } from "../utils/logger";

async function main() {
  const tweetUrl = process.argv[2];

  if (!tweetUrl) {
    console.error("âŒ íŠ¸ìœ„í„° URLì„ ì…ë ¥í•´ì£¼ì„¸ìš”");
    console.log("ì‚¬ìš©ë²•: npm run scrape:twitter <íŠ¸ìœ„í„°_URL>");
    process.exit(1);
  }

  // URL ìœ íš¨ì„± ê²€ì‚¬
  if (!tweetUrl.includes("twitter.com") && !tweetUrl.includes("x.com")) {
    console.error("âŒ ìœ íš¨í•œ íŠ¸ìœ„í„° URLì´ ì•„ë‹™ë‹ˆë‹¤");
    process.exit(1);
  }

  const scraper = new TwitterScraper();

  try {
    console.log("ğŸš€ [1ë‹¨ê³„] ìŠ¤í¬ë˜í•‘ ì‹œì‘");
    console.log("ğŸ“‹ URL:", tweetUrl);

    console.log("ğŸ”§ [2ë‹¨ê³„] ë¸Œë¼ìš°ì € ì´ˆê¸°í™” ì¤‘...");

    // ê°œì„ ëœ ì¬ì‹œë„ ë¡œì§ ì‚¬ìš©
    const tweetData = await scraper.scrapeTweetWithRetry(tweetUrl, 1); // ìµœëŒ€ 1íšŒë§Œ ì‹œë„

    if (!tweetData) {
      console.error("âŒ [ìµœì¢…] ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨");
      process.exit(1);
    }

    console.log("âœ… [4ë‹¨ê³„] ìŠ¤í¬ë˜í•‘ ì„±ê³µ");
    console.log("ğŸ“Š ê²°ê³¼:", {
      id: tweetData.id,
      author: `@${tweetData.author.username}`,
      text: tweetData.text.substring(0, 100) + "...",
      hasTranslation: !!tweetData.textKo,
    });

    console.log("ğŸ’¾ [5ë‹¨ê³„] ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì¤‘...");
    await saveTweetToSupabase(tweetData);

    console.log("âœ… [ì™„ë£Œ] ëª¨ë“  ì‘ì—… ì™„ë£Œ!");
  } catch (error) {
    console.error("âŒ [ì˜¤ë¥˜]", (error as Error).message);
    process.exit(1);
  } finally {
    console.log("ğŸ§¹ [ì •ë¦¬] ë¸Œë¼ìš°ì € ì¢…ë£Œ");
  }
}

// ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
main().catch(console.error);
