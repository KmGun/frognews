import { callOpenAIWithQueue, getQueueStatus } from '../utils/openai-rate-limiter';
import OpenAI from 'openai';

// OpenAI í´ë¼ì´ì–¸íŠ¸ ìƒì„±
const client = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

async function testQueueSystem() {
  console.log('ğŸ§ª OpenAI API í ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹œì‘\n');

  try {
    // ì—¬ëŸ¬ ê°œì˜ ë™ì‹œ ìš”ì²­ í…ŒìŠ¤íŠ¸
    const testRequests = [
      { text: 'ì¸ê³µì§€ëŠ¥ì´ë€ ë¬´ì—‡ì¸ê°€?', priority: 1 },
      { text: 'ë¨¸ì‹ ëŸ¬ë‹ì˜ ê¸°ë³¸ ê°œë…', priority: 2 },
      { text: 'ë”¥ëŸ¬ë‹ê³¼ ì‹ ê²½ë§', priority: 3 },
      { text: 'ìì—°ì–´ì²˜ë¦¬ ê¸°ìˆ ', priority: 4 },
      { text: 'GPT ëª¨ë¸ì˜ ë°œì „', priority: 5 },
    ];

    console.log(`ğŸ“ ${testRequests.length}ê°œì˜ í…ŒìŠ¤íŠ¸ ìš”ì²­ íì— ì¶”ê°€ ì¤‘...\n`);

    // ëª¨ë“  ìš”ì²­ì„ ë™ì‹œì— íì— ì¶”ê°€
    const promises = testRequests.map((req, index) => 
      callOpenAIWithQueue(
        async () => {
          console.log(`ğŸ”„ ìš”ì²­ ${index + 1} ì‹¤í–‰ ì¤‘: ${req.text}`);
          return await client.chat.completions.create({
            model: 'gpt-4.1',
            messages: [{ role: 'user', content: `${req.text}ì— ëŒ€í•´ í•œ ì¤„ë¡œ ê°„ë‹¨íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”.` }],
            max_tokens: 100,
            temperature: 0.3
          });
        },
        req.text,
        100,
        req.priority
      )
    );

    // í ìƒíƒœ ëª¨ë‹ˆí„°ë§
    const statusInterval = setInterval(() => {
      const status = getQueueStatus();
      console.log(`ğŸ“Š í ìƒíƒœ - ëŒ€ê¸°: ${status.queueLength}, ì²˜ë¦¬ì¤‘: ${status.processing ? 'YES' : 'NO'}, í† í°: ${status.currentTokenUsage}/${Math.floor(30000 * 0.9)}`);
      
      if (status.queueLength === 0 && !status.processing) {
        clearInterval(statusInterval);
      }
    }, 1000);

    // ëª¨ë“  ìš”ì²­ ì™„ë£Œ ëŒ€ê¸°
    const results = await Promise.all(promises);

    console.log('\nâœ… ëª¨ë“  ìš”ì²­ ì™„ë£Œ!\n');

    // ê²°ê³¼ ì¶œë ¥
    results.forEach((result, index) => {
      const content = result.choices[0]?.message?.content?.trim() || 'ì‘ë‹µ ì—†ìŒ';
      console.log(`${index + 1}. ${testRequests[index].text}`);
      console.log(`   ë‹µë³€: ${content}\n`);
    });

    // ìµœì¢… í ìƒíƒœ
    const finalStatus = getQueueStatus();
    console.log('ğŸ“Š ìµœì¢… í ìƒíƒœ:');
    console.log(`   - í ê¸¸ì´: ${finalStatus.queueLength}`);
    console.log(`   - í† í° ì‚¬ìš©ëŸ‰: ${finalStatus.currentTokenUsage}`);
    console.log(`   - ìš”ì²­ ìˆ˜: ${finalStatus.currentRequestCount}`);
    console.log(`   - ë‹¤ìŒ ë¦¬ì…‹ê¹Œì§€: ${Math.ceil(finalStatus.timeUntilReset / 1000)}ì´ˆ`);

  } catch (error) {
    console.error('âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨:', error);
  }
}

// í™˜ê²½ë³€ìˆ˜ ì²´í¬
if (!process.env.OPENAI_API_KEY) {
  console.error('âŒ OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.');
  process.exit(1);
}

// í…ŒìŠ¤íŠ¸ ì‹¤í–‰
testQueueSystem()
  .then(() => {
    console.log('ğŸ‰ í ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!');
    process.exit(0);
  })
  .catch((error) => {
    console.error('âŒ í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ:', error);
    process.exit(1);
  }); 